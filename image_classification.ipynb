{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46142705-0160-40dc-87d5-88ad453fe60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0e72e6-39fa-4dc0-bcbd-bb6c07137523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (1.26.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37621207-c351-4f62-a636-f451d9848ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (1.13.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (10.3.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (2.34.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (2024.6.18)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e49f89-3e3f-42f8-95e7-6955cf510543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\ritesh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5661edc1-4c7f-4e6e-806c-2359fac103fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import canny\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import hough_line\n",
    "\n",
    "# histogram\n",
    "def compute_histogram(image):\n",
    "  hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "  return hist.flatten()\n",
    "\n",
    "def edge_detection_canny(image):\n",
    "    edges = canny(image)\n",
    "    return edges.flatten()\n",
    "\n",
    "# def image_smoothing(image):\n",
    "#   smooth_image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "#   return smooth_image.flatten()\n",
    "\n",
    "# def line_detection_hough(image):\n",
    "#   edges = canny(image)\n",
    "#   hspace, angles, dists = hough_line(edges)\n",
    "#   hspace_flatten = hspace.flatten()\n",
    "#   return hspace_flatten\n",
    "\n",
    "# def connected_components(image):\n",
    "#   labelled_image = label(image)\n",
    "#   props = regionprops(labelled_image)\n",
    "#   return [prop.area for prop in props]\n",
    "\n",
    "def compute_sift(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return descriptors.flatten() if descriptors is not None else np.array([])\n",
    "\n",
    "def pad_or_truncate(features, length):\n",
    "    if len(features) >= length:\n",
    "        return features[:length]\n",
    "    else:\n",
    "        return np.pad(features, (0, length - len(features)), 'constant')\n",
    "\n",
    "# def compute_surf(image):\n",
    "#     surf = cv2.SURF_create()\n",
    "#     keypoints, descriptors = surf.detectAndCompute(image, None)\n",
    "#     return descriptors.flatten() if descriptors is not None else np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f45baaeb-0acd-45bd-99f2-1330aa773a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Set a fixed length for the feature vectors\n",
    "FIXED_FEATURE_LENGTH = 500\n",
    "# function to extract features from all the images\n",
    "def extract_features(images):\n",
    "  features = []\n",
    "\n",
    "  # loop through each image\n",
    "  for image in images:\n",
    "    # new_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    hist_features = compute_histogram(image)\n",
    "    # hist_eq_features = histogram_equalization(image)\n",
    "    # smooth_features = image_smoothing(image)\n",
    "    # sobel_features = edge_detection_sobel(image)\n",
    "    canny_features = edge_detection_canny(image)\n",
    "    # hough_features = line_detection_hough(image)\n",
    "\n",
    "    # connected_features = connected_components(image)\n",
    "    sift_features = compute_sift(image)\n",
    "    # surf_features = compute_surf(new_image)\n",
    "\n",
    "    # combine the features in different set\n",
    "    combined_features = np.concatenate([hist_features, sift_features, canny_features])\n",
    "    # mid_level_features = np.concatenate([smooth_features, connected_features])\n",
    "\n",
    "    # Pad or truncate to the fixed length\n",
    "    combined_features = pad_or_truncate(combined_features, FIXED_FEATURE_LENGTH)\n",
    "\n",
    "    # all_features = np.concatenate([combined_features, mid_level_features])\n",
    "    features.append(combined_features)\n",
    "\n",
    "  return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b05ccbd-38b9-4f64-b75d-552c8e019ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ritesh\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853b2c0c-f2fd-48cc-941b-efe742edfcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5245\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "data_dir = r'C:\\Users\\Ritesh\\Downloads\\dataset_1\\dataset_full'\n",
    "categories = ['Building', 'Glacier', 'Sea', 'Mountains', 'Streets', 'Forest']\n",
    "# Create the sharpening kernel \n",
    "kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]) \n",
    "\n",
    "def load_images(data_dir, categories):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, category in enumerate(categories):\n",
    "        category_dir = os.path.join(data_dir, category)\n",
    "        for files in os.listdir(category_dir):\n",
    "            if files.endswith('.jpg'):\n",
    "                file_path = os.path.join(category_dir, files)\n",
    "                new_image = cv2.imread(file_path)\n",
    "                sharpened_image = cv2.filter2D(new_image, -1, kernel) \n",
    "                if sharpened_image is not None:\n",
    "                    images.append(sharpened_image)\n",
    "                    labels.append(label)\n",
    "                else:\n",
    "                    print(f\"Error reading image: {file_path}\")\n",
    "    return images, labels\n",
    "\n",
    "# Load images and labels\n",
    "images, labels = load_images(data_dir, categories)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6685902f-1f65-4514-9d0a-9ffe3fd108e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.917e+03, 2.900e+01, 3.200e+01, ..., 3.800e+01, 1.700e+01,\n",
       "        4.000e+00],\n",
       "       [6.906e+03, 4.800e+01, 4.300e+01, ..., 8.800e+01, 2.800e+01,\n",
       "        6.000e+00],\n",
       "       [9.840e+02, 1.800e+01, 8.000e+00, ..., 3.000e+00, 0.000e+00,\n",
       "        2.000e+00],\n",
       "       ...,\n",
       "       [8.645e+03, 6.000e+01, 7.400e+01, ..., 4.400e+01, 9.700e+01,\n",
       "        1.400e+01],\n",
       "       [9.044e+03, 5.700e+01, 5.600e+01, ..., 2.600e+01, 7.500e+01,\n",
       "        1.110e+02],\n",
       "       [3.410e+03, 5.100e+01, 5.200e+01, ..., 1.100e+01, 1.030e+02,\n",
       "        4.900e+01]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract features from training and testing images\n",
    "X_train_features = extract_features(X_train)\n",
    "X_test_features = extract_features(X_test)\n",
    "\n",
    "X_train_features\n",
    "X_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "338eecff-835e-4756-863a-192b9f827f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13224, 500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# \n",
    "# Balance the training dataset using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_features, y_train)\n",
    "\n",
    "X_train_resampled.shape\n",
    "# y_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30abca72-e701-49be-8cdb-33fe8124ceb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Best parameters found:  {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy: 0.950317604355717\n",
      "Accuracy: 53.86081982840801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Building       0.23      0.29      0.25       112\n",
      "     Glacier       0.35      0.38      0.37       105\n",
      "         Sea       0.30      0.36      0.33       108\n",
      "   Mountains       0.29      0.30      0.29        92\n",
      "     Streets       0.21      0.34      0.26        91\n",
      "      Forest       0.94      0.73      0.82       541\n",
      "\n",
      "    accuracy                           0.54      1049\n",
      "   macro avg       0.39      0.40      0.39      1049\n",
      "weighted avg       0.62      0.54      0.57      1049\n",
      "\n",
      "[[ 32  11  22  19  21   7]\n",
      " [ 12  40  27  13  12   1]\n",
      " [  8  20  39  25  14   2]\n",
      " [ 20  19  20  28   3   2]\n",
      " [ 28   9   4   7  31  12]\n",
      " [ 39  15  17   6  69 395]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train and Evaluate the k-NN Model\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(KNeighborsClassifier(), param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = clf.predict(X_test_features)\n",
    "\n",
    "print(\"Best parameters found: \", clf.best_params_)\n",
    "print(\"Accuracy:\", clf.best_score_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred)*100)\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87698a71-0786-4573-afd9-ea625d0b54cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mountains\n",
      "Forest\n",
      "Sea\n",
      "Sea\n",
      "Glacier\n",
      "Streets\n",
      "Building\n",
      "Glacier\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Building\n",
      "Building\n",
      "Forest\n",
      "Glacier\n",
      "Building\n",
      "Building\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Streets\n",
      "Sea\n",
      "Forest\n",
      "Streets\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Sea\n",
      "Forest\n",
      "Streets\n",
      "Streets\n",
      "Glacier\n",
      "Sea\n",
      "Streets\n",
      "Sea\n",
      "Building\n",
      "Streets\n",
      "Sea\n",
      "Forest\n",
      "Streets\n",
      "Streets\n",
      "Streets\n",
      "Streets\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Streets\n",
      "Forest\n",
      "Glacier\n",
      "Sea\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Sea\n",
      "Sea\n",
      "Glacier\n",
      "Building\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Sea\n",
      "Forest\n",
      "Sea\n",
      "Glacier\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Mountains\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Streets\n",
      "Building\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Mountains\n",
      "Streets\n",
      "Forest\n",
      "Glacier\n",
      "Building\n",
      "Forest\n",
      "Building\n",
      "Sea\n",
      "Sea\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Sea\n",
      "Building\n",
      "Sea\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Sea\n",
      "Sea\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Building\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Sea\n",
      "Forest\n",
      "Streets\n",
      "Streets\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Streets\n",
      "Mountains\n",
      "Glacier\n",
      "Glacier\n",
      "Building\n",
      "Mountains\n",
      "Building\n",
      "Mountains\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Building\n",
      "Building\n",
      "Building\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Mountains\n",
      "Glacier\n",
      "Streets\n",
      "Building\n",
      "Glacier\n",
      "Mountains\n",
      "Glacier\n",
      "Mountains\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Streets\n",
      "Streets\n",
      "Glacier\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Mountains\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Sea\n",
      "Mountains\n",
      "Mountains\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Streets\n",
      "Forest\n",
      "Glacier\n",
      "Streets\n",
      "Glacier\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Glacier\n",
      "Sea\n",
      "Sea\n",
      "Sea\n",
      "Forest\n",
      "Building\n",
      "Building\n",
      "Streets\n",
      "Sea\n",
      "Glacier\n",
      "Building\n",
      "Building\n",
      "Forest\n",
      "Streets\n",
      "Mountains\n",
      "Building\n",
      "Streets\n",
      "Glacier\n",
      "Streets\n",
      "Mountains\n",
      "Streets\n",
      "Forest\n",
      "Glacier\n",
      "Streets\n",
      "Forest\n",
      "Building\n",
      "Mountains\n",
      "Streets\n",
      "Forest\n",
      "Streets\n",
      "Sea\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Sea\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Building\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Sea\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Building\n",
      "Forest\n",
      "Sea\n",
      "Streets\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Glacier\n",
      "Mountains\n",
      "Forest\n",
      "Mountains\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Sea\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Sea\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Glacier\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Streets\n",
      "Building\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Sea\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Glacier\n",
      "Mountains\n",
      "Streets\n",
      "Building\n",
      "Forest\n",
      "Streets\n",
      "Building\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Sea\n",
      "Glacier\n",
      "Sea\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Glacier\n",
      "Forest\n",
      "Mountains\n",
      "Streets\n",
      "Forest\n",
      "Building\n",
      "Building\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Glacier\n",
      "Building\n",
      "Sea\n",
      "Building\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Building\n",
      "Sea\n",
      "Building\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Streets\n",
      "Sea\n",
      "Glacier\n",
      "Sea\n",
      "Sea\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Sea\n",
      "Building\n",
      "Glacier\n",
      "Sea\n",
      "Mountains\n",
      "Building\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Streets\n",
      "Streets\n",
      "Streets\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Mountains\n",
      "Streets\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Glacier\n",
      "Sea\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Building\n",
      "Forest\n",
      "Building\n",
      "Glacier\n",
      "Forest\n",
      "Sea\n",
      "Glacier\n",
      "Forest\n",
      "Glacier\n",
      "Building\n",
      "Building\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Building\n",
      "Streets\n",
      "Building\n",
      "Forest\n",
      "Mountains\n",
      "Mountains\n",
      "Streets\n",
      "Glacier\n",
      "Streets\n",
      "Building\n",
      "Building\n",
      "Forest\n",
      "Sea\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Sea\n",
      "Forest\n",
      "Glacier\n",
      "Building\n",
      "Forest\n",
      "Glacier\n",
      "Streets\n",
      "Building\n",
      "Streets\n",
      "Forest\n",
      "Streets\n",
      "Glacier\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Sea\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Building\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Mountains\n",
      "Glacier\n",
      "Sea\n",
      "Streets\n",
      "Building\n",
      "Building\n",
      "Sea\n",
      "Streets\n",
      "Sea\n",
      "Forest\n",
      "Sea\n",
      "Streets\n",
      "Streets\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Streets\n",
      "Sea\n",
      "Forest\n",
      "Building\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Building\n",
      "Glacier\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Streets\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Building\n",
      "Streets\n",
      "Streets\n",
      "Mountains\n",
      "Building\n",
      "Forest\n",
      "Sea\n",
      "Streets\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Building\n",
      "Building\n",
      "Mountains\n",
      "Glacier\n",
      "Forest\n",
      "Building\n",
      "Building\n",
      "Building\n",
      "Mountains\n",
      "Forest\n",
      "Streets\n",
      "Sea\n",
      "Streets\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Building\n",
      "Forest\n",
      "Streets\n",
      "Building\n",
      "Sea\n",
      "Glacier\n",
      "Mountains\n",
      "Glacier\n",
      "Mountains\n",
      "Forest\n",
      "Glacier\n",
      "Streets\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Building\n",
      "Mountains\n",
      "Sea\n",
      "Sea\n",
      "Glacier\n",
      "Forest\n",
      "Glacier\n",
      "Glacier\n",
      "Streets\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Sea\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Building\n",
      "Streets\n",
      "Forest\n",
      "Building\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Mountains\n",
      "Glacier\n",
      "Building\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Sea\n",
      "Building\n",
      "Mountains\n",
      "Building\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Building\n",
      "Mountains\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Mountains\n",
      "Sea\n",
      "Sea\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Streets\n",
      "Glacier\n",
      "Forest\n",
      "Mountains\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Mountains\n",
      "Mountains\n",
      "Forest\n",
      "Streets\n",
      "Mountains\n",
      "Mountains\n",
      "Glacier\n",
      "Streets\n",
      "Streets\n",
      "Glacier\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Mountains\n",
      "Mountains\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Glacier\n",
      "Streets\n",
      "Sea\n",
      "Glacier\n",
      "Forest\n",
      "Mountains\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Sea\n",
      "Forest\n",
      "Streets\n",
      "Sea\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Sea\n",
      "Glacier\n",
      "Glacier\n",
      "Sea\n",
      "Glacier\n",
      "Building\n",
      "Building\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Sea\n",
      "Mountains\n",
      "Mountains\n",
      "Forest\n",
      "Sea\n",
      "Sea\n",
      "Glacier\n",
      "Mountains\n",
      "Forest\n",
      "Glacier\n",
      "Sea\n",
      "Forest\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Streets\n",
      "Streets\n",
      "Glacier\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Mountains\n",
      "Building\n",
      "Building\n",
      "Streets\n",
      "Glacier\n",
      "Building\n",
      "Forest\n",
      "Glacier\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Building\n",
      "Sea\n",
      "Glacier\n",
      "Mountains\n",
      "Sea\n",
      "Forest\n",
      "Sea\n",
      "Building\n",
      "Sea\n",
      "Glacier\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Streets\n",
      "Streets\n",
      "Streets\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Streets\n",
      "Mountains\n",
      "Glacier\n",
      "Building\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Building\n",
      "Forest\n",
      "Streets\n",
      "Streets\n",
      "Mountains\n",
      "Sea\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Sea\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Building\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Building\n",
      "Streets\n",
      "Forest\n",
      "Mountains\n",
      "Glacier\n",
      "Mountains\n",
      "Forest\n",
      "Streets\n",
      "Sea\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Sea\n",
      "Forest\n",
      "Glacier\n",
      "Streets\n",
      "Building\n",
      "Forest\n",
      "Streets\n",
      "Sea\n",
      "Building\n",
      "Building\n",
      "Streets\n",
      "Forest\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Mountains\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Forest\n",
      "Streets\n",
      "Glacier\n",
      "Glacier\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Streets\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Glacier\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Mountains\n",
      "Forest\n",
      "Glacier\n",
      "Building\n",
      "Streets\n",
      "Glacier\n",
      "Sea\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Forest\n",
      "Sea\n",
      "Streets\n",
      "Mountains\n",
      "Sea\n",
      "Forest\n",
      "Sea\n",
      "Glacier\n",
      "Sea\n",
      "Streets\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Forest\n",
      "Sea\n",
      "Forest\n",
      "Forest\n",
      "Building\n",
      "Glacier\n",
      "Sea\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Streets\n",
      "Mountains\n",
      "Forest\n",
      "Glacier\n",
      "Glacier\n",
      "Sea\n",
      "Forest\n",
      "Mountains\n",
      "Sea\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Forest\n",
      "Glacier\n",
      "Streets\n",
      "Building\n",
      "Building\n",
      "Forest\n",
      "Forest\n",
      "Streets\n"
     ]
    }
   ],
   "source": [
    "y_pred\n",
    "\n",
    "for pred in y_pred:\n",
    "    print(categories[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8801f2a-8082-41ac-b7b9-e2824b22bd4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m cv_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(data_dir)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# sharpened_image = cv2.filter2D(cv_image, -1, kernel) \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# cv2.imshow('Sharpened Image', sharpened_image)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# cv2.waitKey(0)  # Wait for any key press\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# cv2.destroyAllWindows()  # Close all OpenCV windows\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m prediction \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(features)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "Cell \u001b[1;32mIn[21], line 10\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m      7\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# loop through each image\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# new_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43mhist_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcompute_histogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# hist_eq_features = histogram_equalization(image)\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# smooth_features = image_smoothing(image)\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# sobel_features = edge_detection_sobel(image)\u001b[39;49;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "data_dir = r'C:\\Users\\Ritesh\\Downloads\\dataset_1\\dataset_full\\Building\\1165.jpg'\n",
    "\n",
    "cv_image = cv2.imread(data_dir)\n",
    "# sharpened_image = cv2.filter2D(cv_image, -1, kernel) \n",
    "\n",
    "# cv2.imshow('Sharpened Image', sharpened_image)\n",
    "# cv2.waitKey(0)  # Wait for any key press\n",
    "# cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "features = extract_features(cv_image)\n",
    "prediction = clf.predict(features)\n",
    "print(prediction)\n",
    "print(len(prediction))\n",
    "\n",
    "\n",
    "print(categories[prediction[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49f68a84-2936-438a-8db2-0c72908f12a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classification_model_1.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model to a file\n",
    "joblib_file = \"classification_model_1.pkl\"  \n",
    "joblib.dump(clf, joblib_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2bab3b26-8b85-4eb7-b974-c068ff6e72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# training the random forest classifier\n",
    "model = RandomForestClassifier(n_estimators=500, max_depth=30, random_state=42)\n",
    "model.fit(X_train_features, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "77d1461a-a54d-4629-a4e9-680516ca6788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5319351763584366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Building       0.00      0.00      0.00       112\n",
      "     Glacier       0.00      0.00      0.00       105\n",
      "         Sea       0.47      0.14      0.21       108\n",
      "   Mountains       0.19      0.03      0.06        92\n",
      "     Streets       1.00      0.01      0.02        91\n",
      "      Forest       0.54      1.00      0.70       541\n",
      "\n",
      "    accuracy                           0.53      1049\n",
      "   macro avg       0.37      0.20      0.17      1049\n",
      "weighted avg       0.43      0.53      0.39      1049\n",
      "\n",
      "[[  0   0   2   2   0 108]\n",
      " [  1   0   4   4   0  96]\n",
      " [  0   0  15   6   0  87]\n",
      " [  0   0   6   3   0  83]\n",
      " [  0   0   4   0   1  86]\n",
      " [  0   0   1   1   0 539]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "522d52a6-ad5c-42a4-865a-fe217441cb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_classification_model.pkl']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model to a file\n",
    "joblib_file = \"best_classification_model.pkl\"  \n",
    "joblib.dump(model, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5c19e-074d-4729-9002-1bc8cb5aa959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfe = RFE(estimator=RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=50)\n",
    "X_train_reduced_rfe = rfe.fit_transform(X_train_resampled, y_train_resampled)\n",
    "X_test_reduced_rfe = rfe.transform(X_test_features)\n",
    "\n",
    "model_rfe = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model_rfe.fit(X_train_reduced_rfe, y_train_resampled)\n",
    "y_pred_rfe = model_rfe.predict(X_test_reduced_rfe)\n",
    "print(\"RFE Accuracy:\", accuracy_score(y_test, y_pred_rfe))\n",
    "print(classification_report(y_test, y_pred_rfe, target_names=categories))\n",
    "print(confusion_matrix(y_test, y_pred_rfe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77091e-c515-4ff8-9b0e-3f87c39be8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_scores = cross_val_score(RandomForestClassifier(n_estimators=500, random_state=42), X_train_reduced, y_train, cv=5)\n",
    "print(\"Cross-validation scores:\", cross_val_scores)\n",
    "print(\"Mean cross-validation score:\", cross_val_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001bb909-010d-49fa-a074-74cdb0f7c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model ensembling\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators=500, max_depth=30, random_state=42)\n",
    "clf2 = SVC(probability=True)\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf4 = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('rf', clf1), \n",
    "    ('svc', clf2), \n",
    "    ('knn', clf3),\n",
    "    ('gbc', clf4)\n",
    "], voting='soft')\n",
    "\n",
    "ensemble_model.fit(X_train_reduced, y_train)\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3760d1ab-6b91-44e0-b7a2-f626c3562c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# param_dist = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     # 'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42), param_distributions=param_dist, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "# random_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "# best_model = random_search.best_estimator_\n",
    "# best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75040583-0309-4d92-bb87-7ca27b955451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "# y_pred = best_model.predict(X_test_reduced)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fadaa5c-7ade-40b3-b0a1-ee9c8cfce3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19be074-07b0-4f44-8267-085bbef881a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred, target_names=categories)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a0921-504c-44d8-942b-a0174af3198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test, y_pred_ensemble))\n",
    "print(classification_report(y_test, y_pred_ensemble, target_names=categories))\n",
    "print(confusion_matrix(y_test, y_pred_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a6ab75-466f-407e-a085-ad87eb243244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe8a2c-6d1e-4290-a9c7-0874cd2109f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model to a file\n",
    "joblib_file = \"best_model.pkl\"  \n",
    "joblib.dump(ensemble_model, joblib_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62422f27-9278-4f35-9214-7d3605fd0efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
